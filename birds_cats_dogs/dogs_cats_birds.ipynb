{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445420c9-7b91-469c-b62d-a207bf537695",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import zipfile\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "# Configura√ß√µes de exibi√ß√£o e filtros de avisos\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Silencia logs informativos do TF\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\".*metadata.*\") # Silencia avisos de metadados de imagens\n",
    "\n",
    "print(\"Ambiente configurado com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f4c0a6-e68e-4923-a356-91e38689cc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nota: Em MLOps, esta etapa seria automatizada por um script de data ingestion.\n",
    "\n",
    "# Cria a estrutura de diret√≥rios para os modelos pr√©-treinados\n",
    "import os\n",
    "\n",
    "model_dirs = [\n",
    "    '/tmp/model-balanced/variables',\n",
    "    '/tmp/history-balanced',\n",
    "    '/tmp/model-imbalanced/variables',\n",
    "    '/tmp/history-imbalanced',\n",
    "    '/tmp/model-augmented/variables',\n",
    "    '/tmp/history-augmented'\n",
    "]\n",
    "\n",
    "for dir_path in model_dirs:\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "print(\"Estrutura de diret√≥rios criada. Iniciando downloads...\\n\")\n",
    "\n",
    "# Defini√ß√£o dos links e destinos\n",
    "# Datasets originais\n",
    "#!wget https://storage.googleapis.com/mlep-public/course_1/week2/kagglecatsanddogs_3367a.zip\n",
    "#!wget https://storage.googleapis.com/mlep-public/course_1/week2/CUB_200_2011.tar\n",
    "\n",
    "# Modelos pr√©-treinados\n",
    "# O par√¢metro -P define o diret√≥rio de destino\n",
    "\n",
    "!wget -q -P /tmp/model-balanced/ https://storage.googleapis.com/mlep-public/course_1/week2/model-balanced/saved_model.pb\n",
    "!wget -q -P /tmp/model-balanced/variables/ https://storage.googleapis.com/mlep-public/course_1/week2/model-balanced/variables/variables.data-00000-of-00001\n",
    "!wget -q -P /tmp/model-balanced/variables/ https://storage.googleapis.com/mlep-public/course_1/week2/model-balanced/variables/variables.index\n",
    "!wget -q -P /tmp/history-balanced/ https://storage.googleapis.com/mlep-public/course_1/week2/history-balanced/history-balanced.csv\n",
    "\n",
    "!wget -q -P /tmp/model-imbalanced/ https://storage.googleapis.com/mlep-public/course_1/week2/model-imbalanced/saved_model.pb\n",
    "!wget -q -P /tmp/model-imbalanced/variables/ https://storage.googleapis.com/mlep-public/course_1/week2/model-imbalanced/variables/variables.data-00000-of-00001\n",
    "!wget -q -P /tmp/model-imbalanced/variables/ https://storage.googleapis.com/mlep-public/course_1/week2/model-imbalanced/variables/variables.index\n",
    "!wget -q -P /tmp/history-imbalanced/ https://storage.googleapis.com/mlep-public/course_1/week2/history-imbalanced/history-imbalanced.csv\n",
    "\n",
    "!wget -q -P /tmp/model-augmented/ https://storage.googleapis.com/mlep-public/course_1/week2/model-augmented/saved_model.pb\n",
    "!wget -q -P /tmp/model-augmented/variables/ https://storage.googleapis.com/mlep-public/course_1/week2/model-augmented/variables/variables.data-00000-of-00001\n",
    "!wget -q -P /tmp/model-augmented/variables/ https://storage.googleapis.com/mlep-public/course_1/week2/model-augmented/variables/variables.index\n",
    "!wget -q -P /tmp/history-augmented/ https://storage.googleapis.com/mlep-public/course_1/week2/history-augmented/history-augmented.csv\n",
    "\n",
    "print(\"\\n‚úÖ Downloads conclu√≠dos!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c2a8f2-03f2-4686-a9c3-43af5a57cc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defini√ß√£o de caminhos\n",
    "cats_and_dogs_zip = 'kagglecatsanddogs_3367a.zip'\n",
    "caltech_birds_tar = 'CUB_200_2011.tar'\n",
    "\n",
    "base_dir = '/tmp/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab7ec1b-a2fb-40fa-89af-2cdef7a9c27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra√ß√£o dos arquivos compactados\n",
    "with zipfile.ZipFile(cats_and_dogs_zip, 'r') as my_zip:\n",
    "  my_zip.extractall(base_dir)\n",
    "with tarfile.open(caltech_birds_tar, 'r') as my_tar:\n",
    "  my_tar.extractall(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a666d9-e502-4ce2-8f6a-9bb03bf4bce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mapeamento dos diret√≥rios de C√£es e Gatos (j√° v√™m organizados)\n",
    "base_dogs_dir = os.path.join(base_dir, 'PetImages/Dog')\n",
    "base_cats_dir = os.path.join(base_dir, 'PetImages/Cat')\n",
    "\n",
    "print(f\"Existem {len(os.listdir(base_dogs_dir))} imagens de c√£es\")\n",
    "print(f\"Existem {len(os.listdir(base_cats_dir))} imagens de gatos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826b9fd8-644a-4889-8ee6-652a51a5839f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_birds_dir = '/tmp/data/CUB_200_2011/images'\n",
    "base_birds_dir = os.path.join(base_dir, 'PetImages/Bird')\n",
    "\n",
    "os.makedirs(base_birds_dir, exist_ok=True)\n",
    "\n",
    "moved_count = 0\n",
    "skipped_count = 0\n",
    "\n",
    "for subdir in os.listdir(raw_birds_dir):\n",
    "    subdir_path = os.path.join(raw_birds_dir, subdir)\n",
    "\n",
    "    if not os.path.isdir(subdir_path):\n",
    "        continue\n",
    "\n",
    "    for image in os.listdir(subdir_path):\n",
    "        src = os.path.join(subdir_path, image)\n",
    "\n",
    "        # Novo nome = nome da esp√©cie + nome original da imagem\n",
    "        new_name = f\"{subdir}__{image}\"\n",
    "        dst = os.path.join(base_birds_dir, new_name)\n",
    "\n",
    "        if not os.path.exists(dst):\n",
    "            shutil.move(src, dst)\n",
    "            moved_count += 1\n",
    "        else:\n",
    "            skipped_count += 1\n",
    "\n",
    "print(f\"P√°ssaros movidos com sucesso: {moved_count}\")\n",
    "print(f\"P√°ssaros ignorados (nome duplicado): {skipped_count}\")\n",
    "print(f\"Total de imagens em Bird/: {len(os.listdir(base_birds_dir))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e189cc35-11bc-4bca-9552-06f529bf0ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# Exibe uma amostra de cada classe para valida√ß√£o visual\n",
    "# Isso √© importante para detectar problemas como imagens corrompidas ou mal rotuladas\n",
    "\n",
    "print(\"Exemplo de uma imagem de gato:\")\n",
    "display(Image(filename=f\"{os.path.join(base_cats_dir, os.listdir(base_cats_dir)[0])}\"))\n",
    "print(\"\\nExemplo de uma imagem de c√£o:\")\n",
    "display(Image(filename=f\"{os.path.join(base_dogs_dir, os.listdir(base_dogs_dir)[0])}\"))\n",
    "print(\"\\nExemplo de uma imagem de passaro:\")\n",
    "display(Image(filename=f\"{os.path.join(base_birds_dir, os.listdir(base_birds_dir)[0])}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068fe829-eb2a-4439-9372-b76705dd1f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estrutura de diret√≥rios para organiza√ß√£o do dataset\n",
    "# Padr√£o MLOps: /train/{classe} e /eval/{classe}\n",
    "# Isso facilita o uso de geradores de dados do TensorFlow/Keras\n",
    "\n",
    "train_eval_dirs = ['train/cats', 'train/dogs', 'train/birds', \n",
    "                   'eval/cats', 'eval/dogs', 'eval/birds']\n",
    "\n",
    "# Cria os diret√≥rios de forma segura (evita erro se j√° existirem)\n",
    "for dir in train_eval_dirs:\n",
    "    if not os.path.exists(os.path.join(base_dir, dir)):\n",
    "        os.makedirs(os.path.join(base_dir, dir))\n",
    "\n",
    "print(\"Estrutura de diret√≥rios criada com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48013bd8-5016-4ada-ac1b-94d57f634531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a fun√ß√£o para mover uma parte das imagens do diretorio original para os diretorios de treino e avalia√ß√£o\n",
    "def move_to_destination(origin, destination, percentage_split):\n",
    "    \"\"\"\n",
    "    Move uma porcentagem das imagens de um diret√≥rio de origem para um destino.\n",
    "    \n",
    "    Par√¢metros:\n",
    "    -----------\n",
    "    origin : str\n",
    "        Caminho do diret√≥rio de origem contendo as imagens\n",
    "    destination : str\n",
    "        Caminho do diret√≥rio de destino\n",
    "    percentage_split : float\n",
    "        Porcentagem de imagens a mover (ex: 0.7 = 70%)\n",
    "    \n",
    "    Comportamento:\n",
    "    --------------\n",
    "    - Calcula quantas imagens mover baseado no percentual\n",
    "    - Ordena os arquivos para garantir reprodutibilidade\n",
    "    - Move (n√£o copia) as imagens, economizando espa√ßo em disco\n",
    "    \n",
    "    Exemplo:\n",
    "    --------\n",
    "    Se origin tem 1000 imagens e percentage_split=0.7:\n",
    "    - Move as primeiras 700 imagens (ordenadas alfabeticamente)\n",
    "    - Deixa 300 no diret√≥rio original\n",
    "    \"\"\"\n",
    "    num_images = int(len(os.listdir(origin))*percentage_split)\n",
    "    # zip() combina a lista de nomes com um contador\n",
    "    # sorted() garante ordem consistente (importante para reprodutibilidade)\n",
    "    for image_name, image_number in zip(sorted(os.listdir(origin)), range(num_images)):\n",
    "        shutil.move(os.path.join(origin, image_name), destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a49a67-ec15-41af-9204-a5a5a4fa5df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_to_destination(origin, destination, percentage_split):\n",
    "    \"\"\"\n",
    "    Move uma porcentagem das imagens de um diret√≥rio de origem para um destino.\n",
    "    \n",
    "    Par√¢metros:\n",
    "    -----------\n",
    "    origin : str\n",
    "        Caminho do diret√≥rio de origem contendo as imagens\n",
    "    destination : str\n",
    "        Caminho do diret√≥rio de destino\n",
    "    percentage_split : float\n",
    "        Porcentagem de imagens a mover (ex: 0.7 = 70%)\n",
    "    \n",
    "    Comportamento:\n",
    "    --------------\n",
    "    - Calcula quantas imagens mover baseado no percentual\n",
    "    - Ordena os arquivos para garantir reprodutibilidade\n",
    "    - Move (n√£o copia) as imagens, economizando espa√ßo em disco\n",
    "    - IDEMPOTENTE: ignora arquivos que j√° existem no destino\n",
    "    \n",
    "    Exemplo:\n",
    "    --------\n",
    "    Se origin tem 1000 imagens e percentage_split=0.7:\n",
    "    - Move as primeiras 700 imagens (ordenadas alfabeticamente)\n",
    "    - Deixa 300 no diret√≥rio original\n",
    "    \"\"\"\n",
    "    # Lista apenas arquivos (ignora subdiret√≥rios)\n",
    "    files = [f for f in os.listdir(origin) if os.path.isfile(os.path.join(origin, f))]\n",
    "    \n",
    "    num_images = int(len(files) * percentage_split)\n",
    "    \n",
    "    moved = 0\n",
    "    skipped = 0\n",
    "    \n",
    "    for image_name in sorted(files)[:num_images]:\n",
    "        src = os.path.join(origin, image_name)\n",
    "        dst = os.path.join(destination, image_name)\n",
    "        \n",
    "        # Verifica se o arquivo j√° existe no destino\n",
    "        if not os.path.exists(dst):\n",
    "            shutil.move(src, dst)\n",
    "            moved += 1\n",
    "        else:\n",
    "            # Se j√° existe, remove da origem para manter consist√™ncia\n",
    "            if os.path.exists(src):\n",
    "                os.remove(src)\n",
    "            skipped += 1\n",
    "    \n",
    "    return moved, skipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc4556d-06aa-410b-9f50-749815f4a521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpeza de dados: Remove arquivos problem√°ticos que podem quebrar o treinamento\n",
    "\n",
    "# 1. Remove arquivos vazios (0 bytes)\n",
    "# Imagens corrompidas frequentemente aparecem como arquivos de tamanho zero\n",
    "\n",
    "!find /tmp/data/ -size 0 -exec rm {} +\n",
    "\n",
    "# 2. Remove arquivos que n√£o s√£o JPG\n",
    "# Garante que apenas imagens v√°lidas sejam usadas no pipeline\n",
    "# O dataset pode conter arquivos .db, .txt, etc. que causam erros no TensorFlow\n",
    "\n",
    "!find /tmp/data/ -type f ! -name \"*.jpg\" -exec rm {} +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4a8b95-b109-42aa-b9fb-cebc739abe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relat√≥rio final: Contagem de imagens por classe e conjunto\n",
    "# Importante para detectar desbalanceamento de classes\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"CONJUNTO DE TREINO\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Gatos:    {len(os.listdir(os.path.join(base_dir, 'train/cats')))} imagens\")\n",
    "print(f\"C√£es:     {len(os.listdir(os.path.join(base_dir, 'train/dogs')))} imagens\")\n",
    "print(f\"P√°ssaros: {len(os.listdir(os.path.join(base_dir, 'train/birds')))} imagens\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"CONJUNTO DE AVALIA√á√ÉO\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Gatos:    {len(os.listdir(os.path.join(base_dir, 'eval/cats')))} imagens\")\n",
    "print(f\"C√£es:     {len(os.listdir(os.path.join(base_dir, 'eval/dogs')))} imagens\")\n",
    "print(f\"P√°ssaros: {len(os.listdir(os.path.join(base_dir, 'eval/birds')))} imagens\")\n",
    "\n",
    "# Dica MLOps: Se houver grande desbalanceamento (ex: 10x mais c√£es que gatos),\n",
    "# considere t√©cnicas como class_weight, oversampling ou data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a335de-8065-4afe-b560-e58f28411f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SIMULA√á√ÉO DE CEN√ÅRIO REAL: Dataset Desbalanceado\n",
    "\n",
    "Contexto MLOps:\n",
    "---------------\n",
    "Em produ√ß√£o, √© comum ter datasets desbalanceados onde algumas classes t√™m muito\n",
    "menos exemplos que outras. Exemplos reais:\n",
    "- Detec√ß√£o de fraudes (99% transa√ß√µes normais, 1% fraudes)\n",
    "- Diagn√≥stico m√©dico (doen√ßas raras vs. casos comuns)\n",
    "- Controle de qualidade (produtos defeituosos s√£o minoria)\n",
    "\n",
    "Neste experimento:\n",
    "------------------\n",
    "Simulamos um cen√°rio onde parte das imagens de c√£es e p√°ssaros foi \"perdida\"\n",
    "(deletada, corrompida, ou n√£o coletada):\n",
    "- Gatos: 100% dos dados (classe majorit√°ria)\n",
    "- C√£es: apenas 20% dos dados originais\n",
    "- P√°ssaros: apenas 10% dos dados originais\n",
    "\n",
    "Objetivo:\n",
    "---------\n",
    "Comparar o desempenho de modelos treinados em datasets balanceados vs. desbalanceados\n",
    "e avaliar t√©cnicas de mitiga√ß√£o (class weights, oversampling, data augmentation).\n",
    "\"\"\"\n",
    "\n",
    "# Cria√ß√£o da estrutura de diret√≥rios para o dataset desbalanceado\n",
    "imbalanced_dirs = [f'imbalanced/{dir_path}' for dir_path in train_eval_dirs]\n",
    "\n",
    "for dir_path in imbalanced_dirs:\n",
    "    full_path = os.path.join(base_dir, dir_path)\n",
    "    if not os.path.exists(full_path):\n",
    "        os.makedirs(full_path)\n",
    "\n",
    "print(\"Estrutura de diret√≥rios 'imbalanced' criada.\\n\")\n",
    "\n",
    "\n",
    "# Fun√ß√£o auxiliar para copiar (n√£o mover) uma porcentagem das imagens\n",
    "def copy_with_limit(origin, destination, percentage_split):\n",
    "    \"\"\"\n",
    "    Copia uma porcentagem das imagens de origem para destino.\n",
    "    \n",
    "    Diferen√ßa da fun√ß√£o anterior (move_to_destination):\n",
    "    ----------------------------------------------------\n",
    "    - Usa shutil.COPY em vez de shutil.MOVE\n",
    "    - Preserva os dados originais intactos\n",
    "    - Permite criar m√∫ltiplas vers√µes do dataset (balanced, imbalanced, augmented)\n",
    "    \n",
    "    Par√¢metros:\n",
    "    -----------\n",
    "    origin : str\n",
    "        Diret√≥rio de origem\n",
    "    destination : str\n",
    "        Diret√≥rio de destino\n",
    "    percentage_split : float\n",
    "        Porcentagem de imagens a copiar (0.1 = 10%, 1.0 = 100%)\n",
    "    \"\"\"\n",
    "    num_images = int(len(os.listdir(origin)) * percentage_split)\n",
    "    \n",
    "    for image_name, image_number in zip(sorted(os.listdir(origin)), range(num_images)):\n",
    "        shutil.copy(os.path.join(origin, image_name), destination)\n",
    "\n",
    "\n",
    "# Cria√ß√£o do dataset desbalanceado - TREINO\n",
    "print(\"Criando conjunto de TREINO desbalanceado...\")\n",
    "print(\"  - Gatos: 100% (baseline)\")\n",
    "print(\"  - C√£es: 20% (classe minorit√°ria)\")\n",
    "print(\"  - P√°ssaros: 10% (classe muito minorit√°ria)\\n\")\n",
    "\n",
    "copy_with_limit(\n",
    "    os.path.join(base_dir, 'train/cats'), \n",
    "    os.path.join(base_dir, 'imbalanced/train/cats'), \n",
    "    1.0  # 100% dos gatos\n",
    ")\n",
    "copy_with_limit(\n",
    "    os.path.join(base_dir, 'train/dogs'), \n",
    "    os.path.join(base_dir, 'imbalanced/train/dogs'), \n",
    "    0.2  # 20% dos c√£es\n",
    ")\n",
    "copy_with_limit(\n",
    "    os.path.join(base_dir, 'train/birds'), \n",
    "    os.path.join(base_dir, 'imbalanced/train/birds'), \n",
    "    0.1  # 10% dos p√°ssaros\n",
    ")\n",
    "\n",
    "# Cria√ß√£o do dataset desbalanceado - AVALIA√á√ÉO\n",
    "print(\"Criando conjunto de AVALIA√á√ÉO desbalanceado (mesmas propor√ß√µes)...\\n\")\n",
    "\n",
    "copy_with_limit(\n",
    "    os.path.join(base_dir, 'eval/cats'), \n",
    "    os.path.join(base_dir, 'imbalanced/eval/cats'), \n",
    "    1.0\n",
    ")\n",
    "copy_with_limit(\n",
    "    os.path.join(base_dir, 'eval/dogs'), \n",
    "    os.path.join(base_dir, 'imbalanced/eval/dogs'), \n",
    "    0.2\n",
    ")\n",
    "copy_with_limit(\n",
    "    os.path.join(base_dir, 'eval/birds'), \n",
    "    os.path.join(base_dir, 'imbalanced/eval/birds'), \n",
    "    0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7037e11f-8b28-49cc-a239-0ce1736b4395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relat√≥rio de distribui√ß√£o do dataset desbalanceado\n",
    "# Importante para calcular class_weights e avaliar estrat√©gias de balanceamento\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DATASET DESBALANCEADO - CONJUNTO DE TREINO\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "train_cats_imb = len(os.listdir(os.path.join(base_dir, 'imbalanced/train/cats')))\n",
    "train_dogs_imb = len(os.listdir(os.path.join(base_dir, 'imbalanced/train/dogs')))\n",
    "train_birds_imb = len(os.listdir(os.path.join(base_dir, 'imbalanced/train/birds')))\n",
    "\n",
    "print(f\"Gatos:    {train_cats_imb:>6} imagens (100%)\")\n",
    "print(f\"C√£es:     {train_dogs_imb:>6} imagens ( 20%)\")\n",
    "print(f\"P√°ssaros: {train_birds_imb:>6} imagens ( 10%)\")\n",
    "print(f\"{'‚îÄ' * 60}\")\n",
    "print(f\"Total:    {train_cats_imb + train_dogs_imb + train_birds_imb:>6} imagens\")\n",
    "\n",
    "# C√°lculo da raz√£o de desbalanceamento (imbalance ratio)\n",
    "# M√©trica importante para decidir estrat√©gia de mitiga√ß√£o\n",
    "max_class = train_cats_imb\n",
    "imbalance_ratio_dogs = max_class / train_dogs_imb\n",
    "imbalance_ratio_birds = max_class / train_birds_imb\n",
    "\n",
    "print(f\"\\nRaz√£o de desbalanceamento:\")\n",
    "print(f\"  Gatos/C√£es:     {imbalance_ratio_dogs:.1f}:1\")\n",
    "print(f\"  Gatos/P√°ssaros: {imbalance_ratio_birds:.1f}:1\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DATASET DESBALANCEADO - CONJUNTO DE AVALIA√á√ÉO\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "eval_cats_imb = len(os.listdir(os.path.join(base_dir, 'imbalanced/eval/cats')))\n",
    "eval_dogs_imb = len(os.listdir(os.path.join(base_dir, 'imbalanced/eval/dogs')))\n",
    "eval_birds_imb = len(os.listdir(os.path.join(base_dir, 'imbalanced/eval/birds')))\n",
    "\n",
    "print(f\"Gatos:    {eval_cats_imb:>6} imagens (100%)\")\n",
    "print(f\"C√£es:     {eval_dogs_imb:>6} imagens ( 20%)\")\n",
    "print(f\"P√°ssaros: {eval_birds_imb:>6} imagens ( 10%)\")\n",
    "print(f\"{'‚îÄ' * 60}\")\n",
    "print(f\"Total:    {eval_cats_imb + eval_dogs_imb + eval_birds_imb:>6} imagens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb48ff0-3e50-4272-ad9d-cc3dc17683db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "def create_model():\n",
    "    \"\"\"\n",
    "    Cria uma CNN (Convolutional Neural Network) para classifica√ß√£o de imagens.\n",
    "    \n",
    "    Arquitetura:\n",
    "    ------------\n",
    "    Modelo sequencial com 4 blocos convolucionais + classificador denso\n",
    "    \n",
    "    Blocos Convolucionais:\n",
    "    - Bloco 1: 32 filtros 3x3 ‚Üí MaxPooling 2x2 (extrai features b√°sicas: bordas, texturas)\n",
    "    - Bloco 2: 64 filtros 3x3 ‚Üí MaxPooling 2x2 (features intermedi√°rias: formas)\n",
    "    - Bloco 3: 64 filtros 3x3 ‚Üí MaxPooling 2x2 (padr√µes mais complexos)\n",
    "    - Bloco 4: 128 filtros 3x3 ‚Üí MaxPooling 2x2 (features de alto n√≠vel)\n",
    "    \n",
    "    Classificador:\n",
    "    - Flatten: Converte feature maps 3D em vetor 1D\n",
    "    - Dense(512): Camada totalmente conectada com 512 neur√¥nios\n",
    "    - Dense(3): Camada de sa√≠da com 3 classes (cats, dogs, birds)\n",
    "    \n",
    "    Par√¢metros:\n",
    "    -----------\n",
    "    - Input shape: (150, 150, 3) - imagens RGB de 150x150 pixels\n",
    "    - Activation: ReLU nas camadas ocultas, Softmax na sa√≠da\n",
    "    - Loss: SparseCategoricalCrossentropy (para labels inteiros: 0, 1, 2)\n",
    "    - Optimizer: Adam (learning rate padr√£o = 0.001)\n",
    "    - Metrics: SparseCategoricalAccuracy (acur√°cia de classifica√ß√£o)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    model : tf.keras.Model\n",
    "        Modelo compilado e pronto para treinamento\n",
    "    \"\"\"\n",
    "    \n",
    "    # Defini√ß√£o da arquitetura sequencial\n",
    "    model = models.Sequential([\n",
    "        # Bloco Convolucional 1: Extra√ß√£o de features b√°sicas\n",
    "        layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "        \n",
    "        # Bloco Convolucional 2: Features intermedi√°rias\n",
    "        layers.Conv2D(64, (3,3), activation='relu'),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "        \n",
    "        # Bloco Convolucional 3: Padr√µes mais complexos\n",
    "        layers.Conv2D(64, (3,3), activation='relu'),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "        \n",
    "        # Bloco Convolucional 4: Features de alto n√≠vel\n",
    "        layers.Conv2D(128, (3,3), activation='relu'),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "        \n",
    "        # Classificador\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dense(3, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Compila√ß√£o do modelo\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "        optimizer=optimizers.Adam(),\n",
    "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1b47f3-f98a-4df9-befe-d10749b2af42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancia√ß√£o do modelo para o experimento com dataset desbalanceado\n",
    "imbalanced_model = create_model()\n",
    "\n",
    "# Exibe a arquitetura e contagem de par√¢metros\n",
    "print(\"=\" * 70)\n",
    "print(\"ARQUITETURA DO MODELO - EXPERIMENTO IMBALANCED\")\n",
    "print(\"=\" * 70)\n",
    "print(imbalanced_model.summary())\n",
    "print(\"\\n‚ö†Ô∏è  Nota: Este modelo ser√° treinado com o dataset DESBALANCEADO\")\n",
    "print(\"   (sem class weights ou t√©cnicas de balanceamento)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413b5784-d232-401b-8b32-a05710d63600",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\"\"\"\n",
    "Data Generators: Pipeline de carregamento e pr√©-processamento de imagens\n",
    "\n",
    "Vantagens do ImageDataGenerator:\n",
    "---------------------------------\n",
    "1. Carregamento sob demanda (n√£o precisa carregar tudo na mem√≥ria)\n",
    "2. Normaliza√ß√£o autom√°tica dos pixels\n",
    "3. Suporte a data augmentation (rota√ß√£o, zoom, flip, etc.)\n",
    "4. Integra√ß√£o nativa com model.fit()\n",
    "\n",
    "Configura√ß√£o atual:\n",
    "-------------------\n",
    "- rescale=1./255: Normaliza pixels de [0, 255] para [0, 1]\n",
    "  (Redes neurais convergem melhor com valores pequenos)\n",
    "- SEM data augmentation (ser√° adicionado em experimentos futuros)\n",
    "\"\"\"\n",
    "\n",
    "# Generator para TREINO: apenas normaliza√ß√£o\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Generator para VALIDA√á√ÉO: apenas normaliza√ß√£o (nunca aplicar augmentation em eval!)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Configura√ß√£o do fluxo de dados de TREINO\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '/tmp/data/imbalanced/train',  # Diret√≥rio raiz (cont√©m subpastas cats, dogs, birds)\n",
    "    target_size=(150, 150),         # Redimensiona todas as imagens para 150x150\n",
    "    batch_size=32,                  # N√∫mero de imagens por batch (ajustar conforme mem√≥ria)\n",
    "    class_mode='sparse'             # Labels como inteiros (0, 1, 2) em vez de one-hot\n",
    ")\n",
    "\n",
    "# Configura√ß√£o do fluxo de dados de VALIDA√á√ÉO\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    '/tmp/data/imbalanced/eval',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='sparse'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a113a9-1e17-4cfc-b342-fa08676907f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valida√ß√£o do mapeamento de classes\n",
    "print(\"=\" * 70)\n",
    "print(\"MAPEAMENTO DE CLASSES (Class Indices)\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Treino:    {train_generator.class_indices}\")\n",
    "print(f\"Valida√ß√£o: {validation_generator.class_indices}\")\n",
    "print(\"\\nInterpreta√ß√£o:\")\n",
    "print(\"  - O n√∫mero representa o label que o modelo vai prever\")\n",
    "print(\"  - Exemplo: se o modelo prever '1', significa 'dog'\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Informa√ß√µes adicionais sobre os generators\n",
    "print(f\"\\nTotal de imagens de treino: {train_generator.samples}\")\n",
    "print(f\"Total de imagens de valida√ß√£o: {validation_generator.samples}\")\n",
    "print(f\"N√∫mero de batches por √©poca (treino): {len(train_generator)}\")\n",
    "print(f\"N√∫mero de batches por √©poca (valida√ß√£o): {len(validation_generator)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2313c37-36db-4a77-8894-7a08e645f272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained model and history\n",
    "imbalanced_history = pd.read_csv('/tmp/history-imbalanced/history-imbalanced.csv')\n",
    "imbalanced_model = tf.keras.models.load_model('/tmp/model-imbalanced')  \n",
    "\n",
    "print(\"‚úÖ Modelo e hist√≥rico carregados com sucesso!\")\n",
    "print(f\"√âpocas treinadas: {len(imbalanced_history)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f9c364-ba5a-4a81-882e-48bbeeda05b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_metrics(history):\n",
    "    \"\"\"\n",
    "    Extrai m√©tricas de treinamento de um objeto History ou DataFrame.\n",
    "    \n",
    "    Par√¢metros:\n",
    "    -----------\n",
    "    history : keras.callbacks.History ou pd.DataFrame\n",
    "        Hist√≥rico de treinamento do modelo\n",
    "    \n",
    "    Retorna:\n",
    "    --------\n",
    "    acc, val_acc, loss, val_loss : listas ou pd.Series\n",
    "        M√©tricas de acur√°cia e loss para treino e valida√ß√£o\n",
    "    \"\"\"\n",
    "    \n",
    "    if not isinstance(history, pd.core.frame.DataFrame):\n",
    "        history = history.history\n",
    "    \n",
    "    acc = history['sparse_categorical_accuracy']\n",
    "    val_acc = history['val_sparse_categorical_accuracy']\n",
    "    \n",
    "    loss = history['loss']\n",
    "    val_loss = history['val_loss']\n",
    "    \n",
    "    return acc, val_acc, loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300705dc-6f0f-45f2-b9ef-bf987733d8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_eval(history):\n",
    "    \"\"\"\n",
    "    Plota curvas de acur√°cia e loss para treino vs. valida√ß√£o.\n",
    "    \n",
    "    Visualiza√ß√£o essencial em MLOps para detectar:\n",
    "    - Overfitting: treino continua melhorando, valida√ß√£o piora\n",
    "    - Underfitting: ambos n√£o melhoram\n",
    "    - Converg√™ncia: ambos estabilizam em valores pr√≥ximos\n",
    "    \n",
    "    Par√¢metros:\n",
    "    -----------\n",
    "    history : keras.callbacks.History ou pd.DataFrame\n",
    "        Hist√≥rico de treinamento do modelo\n",
    "    \"\"\"\n",
    "    acc, val_acc, loss, val_loss = get_training_metrics(history)\n",
    "    \n",
    "    # Gr√°fico de Acur√°cia\n",
    "\n",
    "    acc_plot_data = pd.DataFrame({\n",
    "        \"training accuracy\": acc, \n",
    "        \"evaluation accuracy\": val_acc\n",
    "    })\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))  # Cria figura com 2 subplots lado a lado\n",
    "    \n",
    "    # Subplot 1: Acur√°cia\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.lineplot(data=acc_plot_data)\n",
    "    plt.title('Training vs Evaluation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Sparse Categorical Accuracy')\n",
    "    plt.legend(['Training', 'Evaluation'])\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Subplot 2: Loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "\n",
    "    loss_plot_data = pd.DataFrame({\n",
    "        \"training loss\": loss, \n",
    "        \"evaluation loss\": val_loss\n",
    "    })\n",
    "    sns.lineplot(data=loss_plot_data)\n",
    "    plt.title('Training vs Evaluation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(['Training', 'Evaluation'])\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Chama a fun√ß√£o para plotar\n",
    "plot_train_eval(imbalanced_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd0d612-34fc-43c8-a2a0-ff83b7493c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    confusion_matrix, \n",
    "    ConfusionMatrixDisplay, \n",
    "    accuracy_score, \n",
    "    balanced_accuracy_score,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "AVALIA√á√ÉO DO MODELO IMBALANCED\n",
    "\n",
    "Objetivo:\n",
    "---------\n",
    "Avaliar o desempenho do modelo treinado com dataset desbalanceado usando:\n",
    "1. Accuracy Score (m√©trica padr√£o, mas enganosa em datasets desbalanceados)\n",
    "2. Balanced Accuracy Score (compensa o desbalanceamento)\n",
    "3. Confusion Matrix (visualiza erros por classe)\n",
    "4. Propor√ß√£o de erros por classe (identifica classes problem√°ticas)\n",
    "\n",
    "Por que shuffle=False?\n",
    "----------------------\n",
    "Para calcular m√©tricas, precisamos que a ordem das predi√ß√µes corresponda\n",
    "exatamente √† ordem dos labels verdadeiros. Com shuffle=True, essa correspond√™ncia\n",
    "seria perdida.\n",
    "\"\"\"\n",
    "\n",
    "# Cria generator SEM shuffle para manter correspond√™ncia entre predi√ß√µes e labels\n",
    "val_gen_no_shuffle = test_datagen.flow_from_directory(\n",
    "    '/tmp/data/imbalanced/eval',  # Dataset desbalanceado\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='sparse',\n",
    "    shuffle=False  # CR√çTICO: mant√©m ordem para c√°lculo de m√©tricas\n",
    ")\n",
    "\n",
    "# Extrai os labels verdadeiros do generator\n",
    "y_true = val_gen_no_shuffle.classes\n",
    "\n",
    "print(\"Gerando predi√ß√µes no conjunto de valida√ß√£o...\")\n",
    "print(\"(Isso pode levar alguns minutos dependendo do tamanho do dataset)\\n\")\n",
    "\n",
    "# Gera predi√ß√µes para todo o conjunto de valida√ß√£o\n",
    "predictions_imbalanced = imbalanced_model.predict(val_gen_no_shuffle)\n",
    "\n",
    "# Converte probabilidades (softmax) em classes preditas\n",
    "# predictions_imbalanced shape: (n_samples, 3) ‚Üí valores entre 0 e 1\n",
    "# y_pred_imbalanced shape: (n_samples,) ‚Üí valores 0, 1, ou 2\n",
    "y_pred_imbalanced = np.argmax(predictions_imbalanced, axis=1)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"M√âTRICAS DE AVALIA√á√ÉO - MODELO IMBALANCED\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Accuracy Score: % de predi√ß√µes corretas (enganosa em datasets desbalanceados)\n",
    "acc_score = accuracy_score(y_true, y_pred_imbalanced)\n",
    "print(f\"Accuracy Score:          {acc_score:.4f} ({acc_score*100:.2f}%)\")\n",
    "\n",
    "# Balanced Accuracy Score: m√©dia das acur√°cias por classe (melhor para imbalance)\n",
    "balanced_acc = balanced_accuracy_score(y_true, y_pred_imbalanced)\n",
    "print(f\"Balanced Accuracy Score: {balanced_acc:.4f} ({balanced_acc*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è  Nota: Em datasets desbalanceados, Balanced Accuracy √© mais confi√°vel\")\n",
    "print(\"   que Accuracy padr√£o, pois d√° peso igual a todas as classes.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6823a2-2418-46ef-9f3e-728c16499718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula e plota a Confusion Matrix\n",
    "imbalanced_cm = confusion_matrix(y_true, y_pred_imbalanced)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "ConfusionMatrixDisplay(\n",
    "    imbalanced_cm, \n",
    "    display_labels=['birds', 'cats', 'dogs']\n",
    ").plot(values_format=\"d\", cmap='Blues')\n",
    "plt.title('Confusion Matrix - Modelo Imbalanced\\n(Dataset de Valida√ß√£o Desbalanceado)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"INTERPRETA√á√ÉO DA CONFUSION MATRIX\")\n",
    "print(\"=\" * 70)\n",
    "print(\"Linhas: Classes verdadeiras (ground truth)\")\n",
    "print(\"Colunas: Classes preditas pelo modelo\")\n",
    "print(\"Diagonal: Predi√ß√µes corretas\")\n",
    "print(\"Fora da diagonal: Erros de classifica√ß√£o\\n\")\n",
    "\n",
    "# Calcula propor√ß√£o de erros por classe\n",
    "# F√≥rmula: (soma dos erros da linha) / (total de exemplos da classe)\n",
    "misclassified_birds = (imbalanced_cm[0, 1] + imbalanced_cm[0, 2]) / np.sum(imbalanced_cm, axis=1)[0]\n",
    "misclassified_cats = (imbalanced_cm[1, 0] + imbalanced_cm[1, 2]) / np.sum(imbalanced_cm, axis=1)[1]\n",
    "misclassified_dogs = (imbalanced_cm[2, 0] + imbalanced_cm[2, 1]) / np.sum(imbalanced_cm, axis=1)[2]\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PROPOR√á√ÉO DE ERROS POR CLASSE\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"P√°ssaros (birds): {misclassified_birds*100:.2f}% de erros\")\n",
    "print(f\"Gatos (cats):     {misclassified_cats*100:.2f}% de erros\")\n",
    "print(f\"C√£es (dogs):      {misclassified_dogs*100:.2f}% de erros\")\n",
    "\n",
    "# Identifica a classe com maior taxa de erro\n",
    "classes = ['birds', 'cats', 'dogs']\n",
    "errors = [misclassified_birds, misclassified_cats, misclassified_dogs]\n",
    "worst_class = classes[np.argmax(errors)]\n",
    "worst_error = max(errors) * 100\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è  Classe mais problem√°tica: {worst_class} ({worst_error:.2f}% de erros)\")\n",
    "print(\"   Isso √© esperado em datasets desbalanceados: classes minorit√°rias\")\n",
    "print(\"   t√™m menos exemplos para aprender, resultando em mais erros.\\n\")\n",
    "\n",
    "# Classification Report (m√©tricas detalhadas por classe)\n",
    "print(\"=\" * 70)\n",
    "print(\"CLASSIFICATION REPORT (Precision, Recall, F1-Score por classe)\")\n",
    "print(\"=\" * 70)\n",
    "print(classification_report(\n",
    "    y_true, \n",
    "    y_pred_imbalanced, \n",
    "    target_names=['birds', 'cats', 'dogs'],\n",
    "    digits=4\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fac465e-2f20-43dc-a3e3-e8317d12bfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "EXPERIMENTO DE CONTROLE: Modelo Baseline Ing√™nuo\n",
    "\n",
    "Contexto MLOps:\n",
    "---------------\n",
    "Para demonstrar o problema do desbalanceamento, criamos um \"modelo\" que sempre\n",
    "prediz a classe majorit√°ria (cats). Isso mostra como a m√©trica Accuracy pode\n",
    "ser enganosa em datasets desbalanceados.\n",
    "\n",
    "Resultado esperado:\n",
    "-------------------\n",
    "- Accuracy alta (porque a maioria das imagens s√£o gatos)\n",
    "- Balanced Accuracy baixa (porque erra 100% das outras classes)\n",
    "\n",
    "Li√ß√£o:\n",
    "------\n",
    "Sempre use m√∫ltiplas m√©tricas em MLOps. Accuracy sozinha pode esconder problemas graves.\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"EXPERIMENTO: Modelo que sempre prediz 'CATS'\")\n",
    "print(\"=\" * 70)\n",
    "print(\"Objetivo: Demonstrar por que Accuracy sozinha √© enganosa\\n\")\n",
    "\n",
    "# Cria array de predi√ß√µes: tudo = 1 (cats)\n",
    "all_cats = np.ones(y_true.shape)\n",
    "\n",
    "# Calcula m√©tricas\n",
    "acc_all_cats = accuracy_score(y_true, all_cats)\n",
    "balanced_acc_all_cats = balanced_accuracy_score(y_true, all_cats)\n",
    "\n",
    "print(f\"Accuracy Score:          {acc_all_cats:.4f} ({acc_all_cats*100:.2f}%)\")\n",
    "print(f\"Balanced Accuracy Score: {balanced_acc_all_cats:.4f} ({balanced_acc_all_cats*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"‚ö†Ô∏è \" * 35)\n",
    "print(\"AN√ÅLISE CR√çTICA:\")\n",
    "print(f\"  - Um modelo 'burro' que sempre chuta 'cats' tem {acc_all_cats*100:.2f}% de accuracy!\")\n",
    "print(f\"  - Mas Balanced Accuracy revela a verdade: apenas {balanced_acc_all_cats*100:.2f}%\")\n",
    "print(\"  - Isso acontece porque o dataset tem muito mais gatos que outras classes\")\n",
    "print(\"\\nCONCLUS√ÉO MLOps:\")\n",
    "print(\"  ‚úÖ Sempre use Balanced Accuracy, F1-Score, ou Recall por classe\")\n",
    "print(\"  ‚ùå NUNCA confie apenas em Accuracy para datasets desbalanceados\")\n",
    "print(\"‚ö†Ô∏è \" * 35 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1904d3c9-aac1-4a47-9ac3-76cbd613e310",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "COMPARA√á√ÉO: Avalia√ß√£o do mesmo modelo em dataset BALANCEADO\n",
    "\n",
    "Objetivo:\n",
    "---------\n",
    "Avaliar como o modelo imbalanced se comporta quando testado em um dataset\n",
    "balanceado (distribui√ß√£o igual de cats, dogs, birds).\n",
    "\n",
    "Hip√≥tese:\n",
    "---------\n",
    "O modelo deve ter desempenho pior em classes minorit√°rias (dogs, birds),\n",
    "pois foi treinado com poucos exemplos dessas classes.\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"AVALIA√á√ÉO EM DATASET BALANCEADO (para compara√ß√£o)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Cria generator para o dataset balanceado de valida√ß√£o\n",
    "val_gen_balanced = test_datagen.flow_from_directory(\n",
    "    '/tmp/data/eval',  # Dataset balanceado original\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='sparse',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Extrai labels verdadeiros\n",
    "y_true_balanced = val_gen_balanced.classes\n",
    "\n",
    "print(\"Gerando predi√ß√µes no conjunto de valida√ß√£o BALANCEADO...\\n\")\n",
    "\n",
    "# Gera predi√ß√µes\n",
    "predictions_balanced = imbalanced_model.predict(val_gen_balanced)\n",
    "y_pred_balanced = np.argmax(predictions_balanced, axis=1)\n",
    "\n",
    "# Calcula m√©tricas\n",
    "acc_balanced = accuracy_score(y_true_balanced, y_pred_balanced)\n",
    "balanced_acc_balanced = balanced_accuracy_score(y_true_balanced, y_pred_balanced)\n",
    "\n",
    "print(f\"Accuracy Score:          {acc_balanced:.4f} ({acc_balanced*100:.2f}%)\")\n",
    "print(f\"Balanced Accuracy Score: {balanced_acc_balanced:.4f} ({balanced_acc_balanced*100:.2f}%)\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_balanced = confusion_matrix(y_true_balanced, y_pred_balanced)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "ConfusionMatrixDisplay(\n",
    "    cm_balanced, \n",
    "    display_labels=['birds', 'cats', 'dogs']\n",
    ").plot(values_format=\"d\", cmap='Greens')\n",
    "plt.title('Confusion Matrix - Modelo Imbalanced\\n(Dataset de Valida√ß√£o BALANCEADO)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"COMPARA√á√ÉO: Imbalanced vs Balanced Evaluation Set\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Balanced Accuracy (eval imbalanced): {balanced_acc:.4f}\")\n",
    "print(f\"Balanced Accuracy (eval balanced):   {balanced_acc_balanced:.4f}\")\n",
    "print(f\"Diferen√ßa: {abs(balanced_acc - balanced_acc_balanced):.4f}\")\n",
    "print(\"\\nüí° Insight: A diferen√ßa mostra o impacto do desbalanceamento no desempenho real.\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8823f9ae-1157-4387-81ce-c9e3a96f9aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "EXPERIMENTO 2: MODELO TREINADO COM DATASET BALANCEADO\n",
    "\n",
    "Objetivo:\n",
    "---------\n",
    "Treinar o mesmo modelo (mesma arquitetura) com um dataset balanceado\n",
    "(distribui√ß√£o igual de cats, dogs, birds) e comparar com o modelo imbalanced.\n",
    "\n",
    "Hip√≥tese:\n",
    "---------\n",
    "O modelo balanceado deve ter:\n",
    "- Balanced Accuracy maior\n",
    "- Desempenho mais uniforme entre as classes\n",
    "- Menos vi√©s para a classe majorit√°ria\n",
    "\n",
    "Configura√ß√£o:\n",
    "-------------\n",
    "- Arquitetura: Id√™ntica ao modelo imbalanced (para compara√ß√£o justa)\n",
    "- Dataset: /tmp/data/train e /tmp/data/eval (balanceados)\n",
    "- Sem data augmentation (ser√° adicionado no Experimento 3)\n",
    "\"\"\"\n",
    "\n",
    "# Instancia um novo modelo com a mesma arquitetura\n",
    "balanced_model = create_model()\n",
    "\n",
    "# Configura√ß√£o dos data generators (apenas normaliza√ß√£o, sem augmentation)\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Generator de treino - dataset BALANCEADO\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '/tmp/data/train',  # Dataset balanceado\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='sparse'\n",
    ")\n",
    "\n",
    "# Generator de valida√ß√£o - dataset BALANCEADO\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    '/tmp/data/eval',  # Dataset balanceado\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='sparse'\n",
    ")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"CONFIGURA√á√ÉO DO EXPERIMENTO - MODELO BALANCEADO\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Treino - Total de imagens: {train_generator.samples}\")\n",
    "print(f\"Treino - Distribui√ß√£o: {train_generator.class_indices}\")\n",
    "print(f\"\\nValida√ß√£o - Total de imagens: {validation_generator.samples}\")\n",
    "print(f\"Valida√ß√£o - Distribui√ß√£o: {validation_generator.class_indices}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb63cb96-0a18-46df-a393-c018e2b27692",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CARREGAMENTO DO MODELO PR√â-TREINADO BALANCEADO\n",
    "\n",
    "Nota:\n",
    "-----\n",
    "Em vez de treinar do zero (o que levaria ~30-60 minutos), carregamos\n",
    "um modelo j√° treinado com o dataset balanceado.\n",
    "\n",
    "Em produ√ß√£o MLOps, voc√™ faria:\n",
    "- Treinar com model.fit()\n",
    "- Salvar com model.save()\n",
    "- Versionar com MLflow ou DVC\n",
    "- Registrar m√©tricas e hiperpar√¢metros\n",
    "\"\"\"\n",
    "\n",
    "# Carrega o hist√≥rico de treinamento (CSV com m√©tricas por √©poca)\n",
    "balanced_history = pd.read_csv('/tmp/history-balanced/history-balanced.csv')\n",
    "\n",
    "# Carrega o modelo treinado (SavedModel format)\n",
    "balanced_model = tf.keras.models.load_model('/tmp/model-balanced')\n",
    "\n",
    "print(\"‚úÖ Modelo balanceado e hist√≥rico carregados com sucesso!\")\n",
    "print(f\"√âpocas treinadas: {len(balanced_history)}\")\n",
    "print(f\"Melhor val_accuracy: {balanced_history['val_sparse_categorical_accuracy'].max():.4f}\")\n",
    "print(f\"Melhor val_loss: {balanced_history['val_loss'].min():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b1e7d6-cdc3-4b70-a21c-267b12e7a6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "AVALIA√á√ÉO DO MODELO BALANCEADO\n",
    "\n",
    "Processo:\n",
    "---------\n",
    "1. Cria generator sem shuffle (para manter correspond√™ncia labels/predi√ß√µes)\n",
    "2. Gera predi√ß√µes para todo o conjunto de valida√ß√£o\n",
    "3. Calcula m√©tricas (Accuracy, Balanced Accuracy)\n",
    "4. Plota Confusion Matrix\n",
    "\"\"\"\n",
    "\n",
    "# Cria generator SEM shuffle para avalia√ß√£o\n",
    "val_gen_no_shuffle = test_datagen.flow_from_directory(\n",
    "    '/tmp/data/eval',  # Dataset balanceado\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='sparse',\n",
    "    shuffle=False  # CR√çTICO: mant√©m ordem para m√©tricas\n",
    ")\n",
    "\n",
    "# Extrai labels verdadeiros\n",
    "y_true = val_gen_no_shuffle.classes\n",
    "\n",
    "print(\"Gerando predi√ß√µes no conjunto de valida√ß√£o balanceado...\")\n",
    "print(\"(Isso pode levar alguns minutos)\\n\")\n",
    "\n",
    "# Gera predi√ß√µes\n",
    "predictions_balanced = balanced_model.predict(val_gen_no_shuffle)\n",
    "\n",
    "# Converte probabilidades (softmax) em classes preditas\n",
    "y_pred_balanced = np.argmax(predictions_balanced, axis=1)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"M√âTRICAS DE AVALIA√á√ÉO - MODELO BALANCEADO\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Accuracy Score\n",
    "acc_balanced = accuracy_score(y_true, y_pred_balanced)\n",
    "print(f\"Accuracy Score:          {acc_balanced:.4f} ({acc_balanced*100:.2f}%)\")\n",
    "\n",
    "# Balanced Accuracy Score\n",
    "balanced_acc_balanced = balanced_accuracy_score(y_true, y_pred_balanced)\n",
    "print(f\"Balanced Accuracy Score: {balanced_acc_balanced:.4f} ({balanced_acc_balanced*100:.2f}%)\")\n",
    "\n",
    "print(\"\\nüí° Nota: Com dataset balanceado, Accuracy e Balanced Accuracy\")\n",
    "print(\"   devem ser pr√≥ximas (diferen√ßa < 2-3%).\\n\")\n",
    "\n",
    "# Confusion Matrix\n",
    "balanced_cm = confusion_matrix(y_true, y_pred_balanced)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "ConfusionMatrixDisplay(\n",
    "    balanced_cm, \n",
    "    display_labels=['birds', 'cats', 'dogs']\n",
    ").plot(values_format=\"d\", cmap='Greens')\n",
    "plt.title('Confusion Matrix - Modelo Balanceado\\n(Dataset de Valida√ß√£o Balanceado)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# An√°lise de erros por classe\n",
    "misclassified_birds = (balanced_cm[0, 1] + balanced_cm[0, 2]) / np.sum(balanced_cm, axis=1)[0]\n",
    "misclassified_cats = (balanced_cm[1, 0] + balanced_cm[1, 2]) / np.sum(balanced_cm, axis=1)[1]\n",
    "misclassified_dogs = (balanced_cm[2, 0] + balanced_cm[2, 1]) / np.sum(balanced_cm, axis=1)[2]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PROPOR√á√ÉO DE ERROS POR CLASSE\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"P√°ssaros (birds): {misclassified_birds*100:.2f}% de erros\")\n",
    "print(f\"Gatos (cats):     {misclassified_cats*100:.2f}% de erros\")\n",
    "print(f\"C√£es (dogs):      {misclassified_dogs*100:.2f}% de erros\")\n",
    "\n",
    "# Calcula desvio padr√£o dos erros (quanto mais baixo, mais uniforme)\n",
    "errors = [misclassified_birds, misclassified_cats, misclassified_dogs]\n",
    "error_std = np.std(errors)\n",
    "\n",
    "print(f\"\\nDesvio padr√£o dos erros: {error_std:.4f}\")\n",
    "print(\"üí° Quanto menor o desvio, mais uniforme o desempenho entre classes.\")\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(\"=\" * 70)\n",
    "print(classification_report(\n",
    "    y_true,\n",
    "    y_pred_balanced,\n",
    "    target_names=['birds', 'cats', 'dogs'],\n",
    "    digits=4\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3566134d-8f78-4298-aba0-ff2e934b8b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_history = pd.read_csv('/tmp/history-augmented/history-augmented.csv')\n",
    "augmented_model = tf.keras.models.load_model('/tmp/model-augmented')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41a569d-6a94-444a-a785-61492362030a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "EXPERIMENTO 3: TREINAMENTO COM DATA AUGMENTATION\n",
    "\n",
    "Objetivo:\n",
    "---------\n",
    "Combater overfitting atrav√©s de data augmentation (aumento artificial do dataset).\n",
    "\n",
    "O que √© Data Augmentation?\n",
    "---------------------------\n",
    "T√©cnica que aplica transforma√ß√µes aleat√≥rias nas imagens de treino para criar\n",
    "varia√ß√µes artificiais, for√ßando o modelo a aprender features mais robustas.\n",
    "\n",
    "Transforma√ß√µes aplicadas:\n",
    "--------------------------\n",
    "- rotation_range=50: Rota√ß√£o aleat√≥ria de at√© 50 graus\n",
    "- width_shift_range=0.15: Deslocamento horizontal de at√© 15%\n",
    "- height_shift_range=0.15: Deslocamento vertical de at√© 15%\n",
    "- shear_range=0.2: Distor√ß√£o de cisalhamento de at√© 20%\n",
    "- zoom_range=0.2: Zoom in/out de at√© 20%\n",
    "- horizontal_flip=True: Espelhamento horizontal aleat√≥rio\n",
    "\n",
    "Por que isso funciona?\n",
    "-----------------------\n",
    "- Aumenta artificialmente o tamanho do dataset\n",
    "- For√ßa o modelo a aprender features invariantes a transforma√ß√µes\n",
    "- Reduz overfitting (modelo n√£o \"decora\" as imagens exatas)\n",
    "- Melhora generaliza√ß√£o para imagens em condi√ß√µes variadas\n",
    "\n",
    "IMPORTANTE:\n",
    "-----------\n",
    "Data augmentation √© aplicado APENAS no treino, NUNCA na valida√ß√£o/teste!\n",
    "\"\"\"\n",
    "\n",
    "# Instancia um novo modelo com a mesma arquitetura\n",
    "augmented_model = create_model()\n",
    "\n",
    "# Generator de TREINO com data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,              # Normaliza√ß√£o (sempre necess√°ria)\n",
    "    rotation_range=50,           # Rota√ß√£o: simula diferentes √¢ngulos de captura\n",
    "    width_shift_range=0.15,      # Shift horizontal: simula descentramento\n",
    "    height_shift_range=0.15,     # Shift vertical: simula descentramento\n",
    "    shear_range=0.2,             # Cisalhamento: simula perspectivas diferentes\n",
    "    zoom_range=0.2,              # Zoom: simula diferentes dist√¢ncias\n",
    "    horizontal_flip=True         # Espelhamento: dobra o dataset (gato da esquerda = gato da direita)\n",
    ")\n",
    "\n",
    "# Generator de VALIDA√á√ÉO sem augmentation (apenas normaliza√ß√£o)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Cria os generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '/tmp/data/train',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='sparse'\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    '/tmp/data/eval',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='sparse'\n",
    ")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"CONFIGURA√á√ÉO DO EXPERIMENTO - MODELO COM DATA AUGMENTATION\")\n",
    "print(\"=\" * 70)\n",
    "print(\"Transforma√ß√µes aplicadas no TREINO:\")\n",
    "print(\"  - Rota√ß√£o: at√© 50¬∞\")\n",
    "print(\"  - Deslocamento: at√© 15% (horizontal e vertical)\")\n",
    "print(\"  - Cisalhamento: at√© 20%\")\n",
    "print(\"  - Zoom: at√© 20%\")\n",
    "print(\"  - Espelhamento horizontal: Sim\")\n",
    "print(\"\\nValida√ß√£o: APENAS normaliza√ß√£o (sem augmentation)\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28a5d45-cfb7-4cf7-b23d-2e61a9bbd268",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array, array_to_img, load_img\n",
    "import random\n",
    "\n",
    "def display_transformations(gen, title=\"Transforma√ß√µes Aplicadas\"):\n",
    "    \"\"\"\n",
    "    Visualiza exemplos de transforma√ß√µes aplicadas por um ImageDataGenerator.\n",
    "    \n",
    "    Par√¢metros:\n",
    "    -----------\n",
    "    gen : ImageDataGenerator\n",
    "        Generator configurado com transforma√ß√µes\n",
    "    title : str\n",
    "        T√≠tulo para o conjunto de transforma√ß√µes\n",
    "    \n",
    "    Utilidade MLOps:\n",
    "    ----------------\n",
    "    Permite validar visualmente se as transforma√ß√µes s√£o realistas.\n",
    "    Transforma√ß√µes muito extremas podem gerar imagens irreconhec√≠veis,\n",
    "    prejudicando o treinamento em vez de ajudar.\n",
    "    \"\"\"\n",
    "    train_birds_dir = \"/tmp/data/train/birds\"\n",
    "    \n",
    "    # Seleciona uma imagem aleat√≥ria de p√°ssaro\n",
    "    bird_images = os.listdir(train_birds_dir)\n",
    "    random_index = random.randint(0, len(bird_images) - 1)\n",
    "    sample_image_path = os.path.join(train_birds_dir, bird_images[random_index])\n",
    "    \n",
    "    # Carrega e prepara a imagem\n",
    "    sample_image = load_img(sample_image_path, target_size=(150, 150))\n",
    "    sample_array = img_to_array(sample_image)\n",
    "    sample_array = sample_array[None, :]  # Adiciona dimens√£o de batch\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(title)\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Imagem original: {bird_images[random_index]}\\n\")\n",
    "    \n",
    "    # Exibe a imagem original\n",
    "    print(\"IMAGEM ORIGINAL:\")\n",
    "    display(sample_image)\n",
    "    \n",
    "    # Gera e exibe 4 transforma√ß√µes aleat√≥rias\n",
    "    print(\"\\nTRANSFORMA√á√ïES GERADAS:\")\n",
    "    for iteration, array in zip(range(4), gen.flow(sample_array, batch_size=1)):\n",
    "        array = np.squeeze(array)  # Remove dimens√£o de batch\n",
    "        img = array_to_img(array)\n",
    "        print(f\"\\nTransforma√ß√£o #{iteration + 1}:\")\n",
    "        display(img)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70 + \"\\n\")\n",
    "\n",
    "\n",
    "# Visualiza transforma√ß√µes MODERADAS (usadas no treinamento)\n",
    "print(\"üîç AN√ÅLISE: Transforma√ß√µes Moderadas (Configura√ß√£o de Treino)\")\n",
    "print(\"Objetivo: Verificar se as transforma√ß√µes mant√™m as imagens reconhec√≠veis\\n\")\n",
    "\n",
    "sample_gen_moderate = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=50,\n",
    "    width_shift_range=0.25,\n",
    "    height_shift_range=0.25,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.25,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "display_transformations(sample_gen_moderate, \"TRANSFORMA√á√ïES MODERADAS\")\n",
    "\n",
    "print(\"‚úÖ An√°lise: As imagens transformadas ainda s√£o reconhec√≠veis?\")\n",
    "print(\"   - Se SIM: Configura√ß√£o adequada para treinamento\")\n",
    "print(\"   - Se N√ÉO: Reduzir intensidade das transforma√ß√µes\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55febbb-622d-4cfb-9caf-3381b0a5c861",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "COMPARA√á√ÉO: Transforma√ß√µes EXTREMAS (n√£o recomendadas)\n",
    "\n",
    "Objetivo:\n",
    "---------\n",
    "Demonstrar o que acontece quando data augmentation √© muito agressivo.\n",
    "\n",
    "Problema:\n",
    "---------\n",
    "Transforma√ß√µes extremas podem:\n",
    "- Gerar imagens irreconhec√≠veis (at√© para humanos)\n",
    "- Confundir o modelo em vez de ajudar\n",
    "- Introduzir artefatos que n√£o existem em dados reais\n",
    "- Prejudicar o desempenho em vez de melhorar\n",
    "\n",
    "Regra de ouro:\n",
    "--------------\n",
    "Se um humano n√£o consegue reconhecer a classe na imagem transformada,\n",
    "o modelo tamb√©m ter√° dificuldade.\n",
    "\"\"\"\n",
    "\n",
    "print(\"‚ö†Ô∏è  AN√ÅLISE: Transforma√ß√µes Extremas (N√ÉO recomendadas)\")\n",
    "print(\"Objetivo: Demonstrar os limites do data augmentation\\n\")\n",
    "\n",
    "# Generator com transforma√ß√µes MUITO agressivas\n",
    "sample_gen_extreme = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=90,           # Rota√ß√£o de at√© 90¬∞ (imagem de cabe√ßa para baixo)\n",
    "    width_shift_range=0.3,       # Deslocamento de 30% (pode cortar partes importantes)\n",
    "    height_shift_range=0.3,      # Deslocamento de 30%\n",
    "    shear_range=0.5,             # Cisalhamento extremo (distorce muito a forma)\n",
    "    zoom_range=0.5,              # Zoom de 50% (pode perder contexto)\n",
    "    vertical_flip=True,          # Espelhamento vertical (animais de cabe√ßa para baixo)\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "display_transformations(sample_gen_extreme, \"TRANSFORMA√á√ïES EXTREMAS (N√ÉO USAR)\")\n",
    "\n",
    "print(\"‚ùå An√°lise: As imagens transformadas est√£o irreconhec√≠veis?\")\n",
    "print(\"   - vertical_flip=True: Animais de cabe√ßa para baixo (n√£o realista)\")\n",
    "print(\"   - rotation_range=90: Pode gerar orienta√ß√µes imposs√≠veis\")\n",
    "print(\"   - shear_range=0.5: Distorce demais a forma original\")\n",
    "print(\"\\nüí° Li√ß√£o MLOps:\")\n",
    "print(\"   Data augmentation deve simular VARIA√á√ïES REALISTAS, n√£o criar\")\n",
    "print(\"   imagens artificiais que nunca ocorreriam em produ√ß√£o.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23a4f9d-5c98-4817-97c4-b5a649d21f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CARREGAMENTO DO MODELO PR√â-TREINADO COM DATA AUGMENTATION\n",
    "\n",
    "Nota:\n",
    "-----\n",
    "Carregamos um modelo j√° treinado com data augmentation para economizar tempo.\n",
    "\n",
    "Expectativa:\n",
    "------------\n",
    "- Menor overfitting (gap menor entre train e eval)\n",
    "- Curvas de treino mais \"ruidosas\" (devido √†s transforma√ß√µes aleat√≥rias)\n",
    "- Melhor generaliza√ß√£o para imagens em condi√ß√µes variadas\n",
    "\"\"\"\n",
    "\n",
    "# Carrega o hist√≥rico de treinamento\n",
    "augmented_history = pd.read_csv('/tmp/history-augmented/history-augmented.csv')\n",
    "\n",
    "# Carrega o modelo treinado\n",
    "augmented_model = tf.keras.models.load_model('/tmp/model-augmented')\n",
    "\n",
    "print(\"‚úÖ Modelo com data augmentation e hist√≥rico carregados com sucesso!\")\n",
    "print(f\"√âpocas treinadas: {len(augmented_history)}\")\n",
    "print(f\"Melhor val_accuracy: {augmented_history['val_sparse_categorical_accuracy'].max():.4f}\")\n",
    "print(f\"Melhor val_loss: {augmented_history['val_loss'].min():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bd5821-c8fb-4035-abe5-c846670fe94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "AVALIA√á√ÉO DO MODELO TREINADO COM DATA AUGMENTATION\n",
    "\n",
    "Hip√≥tese:\n",
    "---------\n",
    "O modelo com augmentation deve ter:\n",
    "- Melhor generaliza√ß√£o (menor gap entre train e eval)\n",
    "- Desempenho similar ou melhor que o modelo balanceado\n",
    "- Maior robustez a varia√ß√µes nas imagens de teste\n",
    "\"\"\"\n",
    "\n",
    "# Cria generator SEM shuffle para avalia√ß√£o\n",
    "val_gen_no_shuffle = test_datagen.flow_from_directory(\n",
    "    '/tmp/data/eval',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='sparse',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Extrai labels verdadeiros\n",
    "y_true = val_gen_no_shuffle.classes\n",
    "\n",
    "print(\"Gerando predi√ß√µes no conjunto de valida√ß√£o...\")\n",
    "print(\"(Isso pode levar alguns minutos)\\n\")\n",
    "\n",
    "# Gera predi√ß√µes\n",
    "predictions_augmented = augmented_model.predict(val_gen_no_shuffle)\n",
    "y_pred_augmented = np.argmax(predictions_augmented, axis=1)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"M√âTRICAS DE AVALIA√á√ÉO - MODELO COM DATA AUGMENTATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Accuracy Score\n",
    "acc_augmented = accuracy_score(y_true, y_pred_augmented)\n",
    "print(f\"Accuracy Score:          {acc_augmented:.4f} ({acc_augmented*100:.2f}%)\")\n",
    "\n",
    "# Balanced Accuracy Score\n",
    "balanced_acc_augmented = balanced_accuracy_score(y_true, y_pred_augmented)\n",
    "print(f\"Balanced Accuracy Score: {balanced_acc_augmented:.4f} ({balanced_acc_augmented*100:.2f}%)\")\n",
    "\n",
    "# Confusion Matrix\n",
    "augmented_cm = confusion_matrix(y_true, y_pred_augmented)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "ConfusionMatrixDisplay(\n",
    "    augmented_cm,\n",
    "    display_labels=['birds', 'cats', 'dogs']\n",
    ").plot(values_format=\"d\", cmap='Purples')\n",
    "plt.title('Confusion Matrix - Modelo com Data Augmentation\\n(Dataset de Valida√ß√£o Balanceado)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# An√°lise de erros por classe\n",
    "misclassified_birds_aug = (augmented_cm[0, 1] + augmented_cm[0, 2]) / np.sum(augmented_cm, axis=1)[0]\n",
    "misclassified_cats_aug = (augmented_cm[1, 0] + augmented_cm[1, 2]) / np.sum(augmented_cm, axis=1)[1]\n",
    "misclassified_dogs_aug = (augmented_cm[2, 0] + augmented_cm[2, 1]) / np.sum(augmented_cm, axis=1)[2]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PROPOR√á√ÉO DE ERROS POR CLASSE\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"P√°ssaros (birds): {misclassified_birds_aug*100:.2f}% de erros\")\n",
    "print(f\"Gatos (cats):     {misclassified_cats_aug*100:.2f}% de erros\")\n",
    "print(f\"C√£es (dogs):      {misclassified_dogs_aug*100:.2f}% de erros\")\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(\"=\" * 70)\n",
    "print(classification_report(\n",
    "    y_true,\n",
    "    y_pred_augmented,\n",
    "    target_names=['birds', 'cats', 'dogs'],\n",
    "    digits=4\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b01e729-050f-4ab0-b23f-aa574d80b086",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "VISUALIZA√á√ÉO DAS CURVAS DE TREINAMENTO - MODELO COM AUGMENTATION\n",
    "\n",
    "An√°lise esperada:\n",
    "-----------------\n",
    "- Curvas de treino mais \"ruidosas\" (devido √†s transforma√ß√µes aleat√≥rias)\n",
    "- Gap menor entre train e eval (menos overfitting)\n",
    "- Converg√™ncia pode ser mais lenta (modelo precisa aprender features mais robustas)\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"CURVAS DE TREINAMENTO - MODELO COM DATA AUGMENTATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "plot_train_eval(augmented_history)\n",
    "\n",
    "print(\"\\nüí° Observa√ß√µes esperadas:\")\n",
    "print(\"   - Curva de treino mais 'ruidosa' (varia√ß√µes entre √©pocas)\")\n",
    "print(\"   - Gap menor entre treino e valida√ß√£o (menos overfitting)\")\n",
    "print(\"   - Accuracy de treino pode ser MENOR que no modelo sem augmentation\")\n",
    "print(\"     (isso √© NORMAL e DESEJ√ÅVEL - significa que o modelo n√£o est√° decorando)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ded9b9-4e54-4269-b1ac-e01656d263fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "COMPARA√á√ÉO FINAL: IMBALANCED vs BALANCED vs AUGMENTED\n",
    "\n",
    "Objetivo:\n",
    "---------\n",
    "Quantificar o impacto de cada t√©cnica no desempenho do modelo.\n",
    "\n",
    "M√©tricas comparadas:\n",
    "--------------------\n",
    "- Balanced Accuracy (m√©trica principal para datasets desbalanceados)\n",
    "- Erro por classe (uniformidade do desempenho)\n",
    "- Gap train-eval (indicador de overfitting)\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"COMPARA√á√ÉO FINAL: 3 EXPERIMENTOS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Cria DataFrame para compara√ß√£o\n",
    "comparison_data = {\n",
    "    'Modelo': ['Imbalanced', 'Balanced', 'Augmented'],\n",
    "    'Balanced Accuracy': [\n",
    "        balanced_acc,           # Do experimento 1\n",
    "        balanced_acc_balanced,  # Do experimento 2\n",
    "        balanced_acc_augmented  # Do experimento 3\n",
    "    ],\n",
    "    'Erro Birds (%)': [\n",
    "        misclassified_birds * 100,\n",
    "        (balanced_cm[0, 1] + balanced_cm[0, 2]) / np.sum(balanced_cm, axis=1)[0] * 100,\n",
    "        misclassified_birds_aug * 100\n",
    "    ],\n",
    "    'Erro Cats (%)': [\n",
    "        misclassified_cats * 100,\n",
    "        (balanced_cm[1, 0] + balanced_cm[1, 2]) / np.sum(balanced_cm, axis=1)[1] * 100,\n",
    "        misclassified_cats_aug * 100\n",
    "    ],\n",
    "    'Erro Dogs (%)': [\n",
    "        misclassified_dogs * 100,\n",
    "        (balanced_cm[2, 0] + balanced_cm[2, 1]) / np.sum(balanced_cm, axis=1)[2] * 100,\n",
    "        misclassified_dogs_aug * 100\n",
    "    ]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Visualiza√ß√£o gr√°fica\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Subplot 1: Balanced Accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(comparison_df['Modelo'], comparison_df['Balanced Accuracy'], \n",
    "        color=['#ff6b6b', '#4ecdc4', '#95e1d3'])\n",
    "plt.title('Balanced Accuracy - Compara√ß√£o dos 3 Modelos')\n",
    "plt.ylabel('Balanced Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Adiciona valores nas barras\n",
    "for i, v in enumerate(comparison_df['Balanced Accuracy']):\n",
    "    plt.text(i, v + 0.02, f'{v:.4f}', ha='center', fontweight='bold')\n",
    "\n",
    "# Subplot 2: Erro por classe\n",
    "plt.subplot(1, 2, 2)\n",
    "x = np.arange(len(comparison_df['Modelo']))\n",
    "width = 0.25\n",
    "\n",
    "plt.bar(x - width, comparison_df['Erro Birds (%)'], width, label='Birds', color='#ff6b6b')\n",
    "plt.bar(x, comparison_df['Erro Cats (%)'], width, label='Cats', color='#4ecdc4')\n",
    "plt.bar(x + width, comparison_df['Erro Dogs (%)'], width, label='Dogs', color='#95e1d3')\n",
    "\n",
    "plt.title('Taxa de Erro por Classe - Compara√ß√£o dos 3 Modelos')\n",
    "plt.ylabel('Taxa de Erro (%)')\n",
    "plt.xticks(x, comparison_df['Modelo'])\n",
    "plt.legend()\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# An√°lise final\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CONCLUS√ïES MLOps\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "best_model_idx = comparison_df['Balanced Accuracy'].idxmax()\n",
    "best_model = comparison_df.loc[best_model_idx, 'Modelo']\n",
    "best_score = comparison_df.loc[best_model_idx, 'Balanced Accuracy']\n",
    "\n",
    "print(f\"üèÜ Melhor modelo: {best_model} (Balanced Accuracy: {best_score:.4f})\")\n",
    "print(\"\\nLi√ß√µes aprendidas:\")\n",
    "print(\"  1. Desbalanceamento de classes prejudica MUITO o desempenho\")\n",
    "print(\"  2. Balancear o dataset √© essencial para treinar modelos justos\")\n",
    "print(\"  3. Data augmentation ajuda a combater overfitting\")\n",
    "print(\"  4. Balanced Accuracy > Accuracy para datasets desbalanceados\")\n",
    "print(\"  5. Sempre analise m√©tricas POR CLASSE, n√£o apenas globais\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59445467-ecc4-4e9f-a972-b6b850bd7a03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
